{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime as dt\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.offline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score, cross_validate\n",
    "\n",
    "\n",
    "# read data\n",
    "in_kaggle = False\n",
    "\n",
    "\n",
    "def get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n",
    "    train_path = ''\n",
    "    test_path = ''\n",
    "    sample_submission_path = ''\n",
    "\n",
    "    if is_in_kaggle:\n",
    "        # running in Kaggle, inside the competition\n",
    "        train_path = '../input/tabular-playground-series-jan-2021/train.csv'\n",
    "        test_path = '../input/tabular-playground-series-jan-2021/test.csv'\n",
    "        sample_submission_path = '../input/tabular-playground-series-jan-2021/sample_submission.csv'\n",
    "    else:\n",
    "        # running locally\n",
    "        train_path = 'data/train.csv'\n",
    "        test_path = 'data/test.csv'\n",
    "        sample_submission_path = 'data/sample_submission.csv'\n",
    "\n",
    "    return train_path, test_path, sample_submission_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2021-01-29 18:42:15.363691\n"
     ]
    }
   ],
   "source": [
    "# main flow\n",
    "start_time = dt.datetime.now()\n",
    "print(\"Started at \", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the training set and labels\n",
    "train_set_path, test_set_path, sample_subm_path = get_data_file_path(in_kaggle)\n",
    "\n",
    "df_train = pd.read_csv(train_set_path)\n",
    "df_test = pd.read_csv(test_set_path)\n",
    "\n",
    "subm = pd.read_csv(sample_subm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.670390</td>\n",
       "      <td>0.811300</td>\n",
       "      <td>0.643968</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>0.284117</td>\n",
       "      <td>0.855953</td>\n",
       "      <td>0.890700</td>\n",
       "      <td>0.285542</td>\n",
       "      <td>0.558245</td>\n",
       "      <td>0.779418</td>\n",
       "      <td>0.921832</td>\n",
       "      <td>0.866772</td>\n",
       "      <td>0.878733</td>\n",
       "      <td>0.305411</td>\n",
       "      <td>7.243043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.388053</td>\n",
       "      <td>0.621104</td>\n",
       "      <td>0.686102</td>\n",
       "      <td>0.501149</td>\n",
       "      <td>0.643790</td>\n",
       "      <td>0.449805</td>\n",
       "      <td>0.510824</td>\n",
       "      <td>0.580748</td>\n",
       "      <td>0.418335</td>\n",
       "      <td>0.432632</td>\n",
       "      <td>0.439872</td>\n",
       "      <td>0.434971</td>\n",
       "      <td>0.369957</td>\n",
       "      <td>0.369484</td>\n",
       "      <td>8.203331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.834950</td>\n",
       "      <td>0.227436</td>\n",
       "      <td>0.301584</td>\n",
       "      <td>0.293408</td>\n",
       "      <td>0.606839</td>\n",
       "      <td>0.829175</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>0.558771</td>\n",
       "      <td>0.587603</td>\n",
       "      <td>0.823312</td>\n",
       "      <td>0.567007</td>\n",
       "      <td>0.677708</td>\n",
       "      <td>0.882938</td>\n",
       "      <td>0.303047</td>\n",
       "      <td>7.776091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.820708</td>\n",
       "      <td>0.160155</td>\n",
       "      <td>0.546887</td>\n",
       "      <td>0.726104</td>\n",
       "      <td>0.282444</td>\n",
       "      <td>0.785108</td>\n",
       "      <td>0.752758</td>\n",
       "      <td>0.823267</td>\n",
       "      <td>0.574466</td>\n",
       "      <td>0.580843</td>\n",
       "      <td>0.769594</td>\n",
       "      <td>0.818143</td>\n",
       "      <td>0.914281</td>\n",
       "      <td>0.279528</td>\n",
       "      <td>6.957716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.935278</td>\n",
       "      <td>0.421235</td>\n",
       "      <td>0.303801</td>\n",
       "      <td>0.880214</td>\n",
       "      <td>0.665610</td>\n",
       "      <td>0.830131</td>\n",
       "      <td>0.487113</td>\n",
       "      <td>0.604157</td>\n",
       "      <td>0.874658</td>\n",
       "      <td>0.863427</td>\n",
       "      <td>0.983575</td>\n",
       "      <td>0.900464</td>\n",
       "      <td>0.935918</td>\n",
       "      <td>0.435772</td>\n",
       "      <td>7.951046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
       "0   1  0.670390  0.811300  0.643968  0.291791  0.284117  0.855953  0.890700   \n",
       "1   3  0.388053  0.621104  0.686102  0.501149  0.643790  0.449805  0.510824   \n",
       "2   4  0.834950  0.227436  0.301584  0.293408  0.606839  0.829175  0.506143   \n",
       "3   5  0.820708  0.160155  0.546887  0.726104  0.282444  0.785108  0.752758   \n",
       "4   8  0.935278  0.421235  0.303801  0.880214  0.665610  0.830131  0.487113   \n",
       "\n",
       "      cont8     cont9    cont10    cont11    cont12    cont13    cont14  \\\n",
       "0  0.285542  0.558245  0.779418  0.921832  0.866772  0.878733  0.305411   \n",
       "1  0.580748  0.418335  0.432632  0.439872  0.434971  0.369957  0.369484   \n",
       "2  0.558771  0.587603  0.823312  0.567007  0.677708  0.882938  0.303047   \n",
       "3  0.823267  0.574466  0.580843  0.769594  0.818143  0.914281  0.279528   \n",
       "4  0.604157  0.874658  0.863427  0.983575  0.900464  0.935918  0.435772   \n",
       "\n",
       "     target  \n",
       "0  7.243043  \n",
       "1  8.203331  \n",
       "2  7.776091  \n",
       "3  6.957716  \n",
       "4  7.951046  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target labels list\n",
    "target = 'target'\n",
    "\n",
    "# drop sig_id from train and test sets\n",
    "df_train = df_train.drop(['id'], axis=1, errors='ignore')\n",
    "df_test = df_test.drop(['id'], axis=1, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified continuous target split\n",
    "# courtesy @tolgadincer and his contribution for https://www.kaggle.com/tolgadincer/continuous-target-stratification\n",
    "\n",
    "def create_folds(df, n_s=5, n_grp=None):\n",
    "    df['Fold'] = -1\n",
    "    \n",
    "    if n_grp is None:\n",
    "        skf = KFold(n_splits=n_s, random_state=42, shuffle=True)\n",
    "        target = df.target\n",
    "    else:\n",
    "        skf = StratifiedKFold(n_splits=n_s, random_state=42, shuffle=False)\n",
    "        df['grp'] = pd.cut(df.target, n_grp, labels=False)\n",
    "        target = df.grp\n",
    "    \n",
    "    for fold_no, (t, v) in enumerate(skf.split(target, target)):\n",
    "        df.loc[v, 'Fold'] = fold_no\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb # LightGBM Model\n",
    "\n",
    "\n",
    "#Additional scklearn functions\n",
    "from sklearn import metrics   \n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
    "\n",
    "\n",
    "# Setting stratified kfold upon the continuous target for future use\n",
    "kfolds = 5\n",
    "df_train = create_folds(df_train, n_s=kfolds) #, n_grp=1000\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# set a hideout fold \n",
    "\n",
    "y = df_train['target']\n",
    "X_train, X_hideout, y_train, y_hideout = train_test_split(df_train, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_hideout = X_hideout.drop(['target', 'Fold', 'grp'], axis=1, errors='ignore').copy()\n",
    "\n",
    "def print_lightgbm_feature_importance(X, y, estimator):\n",
    "    #Print Feature Importance:\n",
    "    estimator.fit(X, y)\n",
    "    predictors = X.columns\n",
    "\n",
    "    feat_imp = pd.Series(estimator.feature_importances_, predictors).sort_values(ascending=False)\n",
    "    feat_imp.nlargest(30).plot(kind='barh', title='Feature Importances', figsize=(8,10))\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    df = feat_imp.to_frame().reset_index()\n",
    "    df = df.rename(columns={'index': 'predictor', 0: \"fi_score\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def model_check(estimator, model_name, model_description):\n",
    "    model_table = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, kfolds):\n",
    "        fold_fit_start_time = dt.datetime.now()\n",
    "        \n",
    "        X_valid = X_train[X_train['Fold'] == i]\n",
    "        y_valid = X_valid['target']\n",
    "        X_valid = X_valid.drop(['target', 'Fold', 'grp'], axis=1, errors='ignore')\n",
    "        \n",
    "        X_tr = X_train[X_train['Fold'] != i]\n",
    "        y_tr = X_tr['target']\n",
    "        X_tr = X_tr.drop(['target', 'Fold', 'grp'], axis=1, errors='ignore')\n",
    "    \n",
    "\n",
    "        fit_model = estimator.fit(X_tr, y_tr)\n",
    "        \n",
    "        pred_tr = estimator.predict(X_tr)\n",
    "        pred_val = estimator.predict(X_valid)\n",
    "\n",
    "        train_score = estimator.score(X_tr, y_tr.values.ravel())\n",
    "        validation_score = estimator.score(X_valid, y_valid.values.ravel())\n",
    "\n",
    "        print('Accuracy of the Regressor on the training set, fold {}: {:.4f}'.format(i, train_score))\n",
    "        print('Accuracy of the Regressor on the validation set, fold {}: {:.4f}'.format(i, validation_score))\n",
    "        \n",
    "        X_hide = X_hideout.copy()\n",
    "        pred_hideout = estimator.predict(X_hide)\n",
    "\n",
    "        hideout_score = estimator.score(X_hide, y_hideout.values.ravel())\n",
    "        print('Accuracy of the Regressor on the hide-out set, fold {}: {:.4f}'.format(i, hideout_score))\n",
    "        \n",
    "        rmse = mean_squared_error(y_hideout, pred_hideout, squared=False)\n",
    "        print('RMSE of the Regressor on the hideout set, fold {}: {:.4f}'.format(i, rmse))\n",
    "\n",
    "        fold_fit_end_time = dt.datetime.now()\n",
    "\n",
    "        fit_time = fold_fit_end_time - fold_fit_start_time\n",
    "\n",
    "        cv_attributes = {\n",
    "            'train_score': round(train_score, 4),\n",
    "            'validation_score': round(validation_score, 4),\n",
    "            'test_score': round(hideout_score, 4),\n",
    "            'test_rmse': round(rmse, 4),\n",
    "            'fit_time': fit_time,\n",
    "        }\n",
    "\n",
    "        if i == 0:\n",
    "            # the initial fold, just initializing the results dataframe\n",
    "            cv_results = pd.DataFrame(data=[cv_attributes])\n",
    "        else:\n",
    "            # appending the results dataframe\n",
    "            fold_result = pd.DataFrame(data=[cv_attributes])\n",
    "            cv_results = pd.concat([cv_results, fold_result])\n",
    "\n",
    "        del X_tr, X_valid, X_hide, y_tr, y_valid\n",
    "\n",
    "    train_score = cv_results['train_score'].mean()\n",
    "    validation_score = cv_results['validation_score'].mean()\n",
    "    test_score = cv_results['test_score'].mean()\n",
    "    test_rmse = cv_results['test_rmse'].mean()\n",
    "    test_std = cv_results['test_score'].std()\n",
    "    fit_time = cv_results['fit_time'].mean()\n",
    "\n",
    "    attributes = {\n",
    "        'model_name': model_name,\n",
    "        'train_score': train_score,\n",
    "        'validation_score': validation_score,\n",
    "        'test_score': test_score,\n",
    "        'test_std': test_std,\n",
    "        'test_rmse': test_rmse,\n",
    "        'fit_time': fit_time,\n",
    "        'description': model_description,\n",
    "    }\n",
    "    \n",
    "    model_table = pd.DataFrame(data=[attributes])\n",
    "    return model_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input data must be 2 dimensional and non empty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-aa31ea0293d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# fit the baseline model with the training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Initial model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Initial baseline\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-49c99a27b997>\u001b[0m in \u001b[0;36mmodel_check\u001b[1;34m(estimator, model_name, model_description)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mpred_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0mpred_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m                              % (self._n_features, n_features))\n\u001b[0;32m    606\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[1;32m--> 607\u001b[1;33m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   2201\u001b[0m         return predictor.predict(data, num_iteration,\n\u001b[0;32m   2202\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2203\u001b[1;33m                                  data_has_header, is_reshape)\n\u001b[0m\u001b[0;32m   2204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2205\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrefit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecay_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot use Dataset instance for prediction, please use raw data instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mpredict_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC_API_PREDICT_NORMAL\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input data must be 2 dimensional and non empty.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'auto'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input data must be 2 dimensional and non empty."
     ]
    }
   ],
   "source": [
    "# initial not tuned model\n",
    "model = lgb.LGBMRegressor(\n",
    "    objective='regression',\n",
    "    metric='rmse',\n",
    "    num_leaves=50, \n",
    "    max_depth=-1, \n",
    "    random_state=314, \n",
    "    silent=True,  \n",
    "    n_jobs=4, \n",
    "    n_estimators=60,\n",
    "    colsample_bytree=0.9,\n",
    "    subsample=0.8,\n",
    "    learning_rate=0.1)\n",
    "\n",
    "# fit the baseline model with the training data\n",
    "result_df = model_check(model, \"Initial model\", \"Initial baseline\")\n",
    "display(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the feature importance of the baseline model\n",
    "feat_imp = print_lightgbm_feature_importance(X_hideout, y_hideout, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tune lightgbm model\n",
    "colsample_bytree_list = [0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "subsample_list = [0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "\n",
    "for colsample in colsample_bytree_list:\n",
    "    for subsample in subsample_list:\n",
    "        model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=50, \n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True,  \n",
    "            n_jobs=4, \n",
    "            n_estimators=60,\n",
    "            colsample_bytree=colsample,\n",
    "            subsample=subsample,\n",
    "            learning_rate=0.1)\n",
    "\n",
    "    description = \"\".join(['Colsample ', str(colsample), '; Subsample ',  str(subsample)])\n",
    "    df = model_check(model, \"Step 1 - ColSample, Subsample\", description)\n",
    "    print(\"Finished checking the model: \", description)\n",
    "    result_df = pd.concat([result_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index().sort_values('test_rmse', \n",
    "                   ascending=True)[\n",
    "                        [ \n",
    "                          'model_name',\t'train_score',\t'validation_score',\n",
    "                         \t'test_score',\t'test_std',\t'test_rmse','fit_time',\t'description'\n",
    "                        ]\n",
    "                              ][:40].style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_leaves_list = [10,15,20,25,30,40,50,60,70,80,90,100,200, 300, 400, 500, 600, 1000]\n",
    "for num in num_leaves_list:\n",
    "    model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=num, \n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            n_estimators=60,\n",
    "            colsample_bytree=0.75,\n",
    "            subsample=0.9,\n",
    "            learning_rate=0.1)\n",
    "\n",
    "    description = \"\".join(['NumLeaves ', str(num)])\n",
    "    df = model_check(model, \"Step 2 - NumLeaves\", description)\n",
    "    print(\"Finished checking the model: \", description)\n",
    "    result_df = pd.concat([result_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index().sort_values('test_rmse', \n",
    "                   ascending=True)[\n",
    "                        [ \n",
    "                          'model_name',\t'train_score',\t'validation_score',\n",
    "                         \t'test_score',\t'test_std',\t'test_rmse','fit_time',\t'description'\n",
    "                        ]\n",
    "                              ][:40].style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_samples = [10, 15, 20, 30, 40, 50, 60,70,80,90,100,120,150,170,200]\n",
    "for num in min_child_samples:\n",
    "    model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=200, \n",
    "            min_child_samples=num, \n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            n_estimators=60,\n",
    "            colsample_bytree=0.75,\n",
    "            subsample=0.9,\n",
    "            learning_rate=0.1)\n",
    "\n",
    "    description = \"\".join(['MinChildSamples ', str(num)])\n",
    "    df = model_check(model, \"Step 3 - MinChildSamples\", description)\n",
    "    print(\"Finished checking the model: \", description)\n",
    "    result_df = pd.concat([result_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index().sort_values('test_rmse', \n",
    "                   ascending=True)[\n",
    "                        [ \n",
    "                          'model_name',\t'train_score',\t'validation_score',\n",
    "                         \t'test_score',\t'test_std',\t'test_rmse', 'fit_time',\t'description'\n",
    "                        ]\n",
    "                              ][:40].style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_child_weights = [0.0001, 0.0005, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "for num in min_child_weights:\n",
    "    model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=200,\n",
    "            min_child_samples=200, \n",
    "            min_child_weights = num,\n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            n_estimators=60,\n",
    "            colsample_bytree=0.8,\n",
    "            subsample=0.9,\n",
    "            learning_rate=0.1)\n",
    "\n",
    "    description = \"\".join(['MinChildWeight ', str(num)])\n",
    "    df = model_check(model, \"Step 4 - MinChildWeight\", description)\n",
    "    print(\"Finished checking the model: \", description)\n",
    "    result_df = pd.concat([result_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index().sort_values('test_rmse', \n",
    "                   ascending=True)[\n",
    "                        [ \n",
    "                          'model_name',\t'train_score',\t'validation_score',\n",
    "                         \t'test_score',\t'test_std',\t'test_rmse', 'fit_time',\t'description'\n",
    "                        ]\n",
    "                              ][:40].style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "reg_alphas = [0.0, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1,2,3]\n",
    "for num in reg_alphas:\n",
    "    model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=200,\n",
    "            min_child_samples=200,\n",
    "            reg_alpha=num,\n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            n_estimators=60,\n",
    "            colsample_bytree=0.75,\n",
    "            subsample=0.9,\n",
    "            learning_rate=0.1)\n",
    "\n",
    "    description = \"\".join(['RegAlpha ', str(num)])\n",
    "    df = model_check(model, \"Step 5 - RegAlpha\", description)\n",
    "    print(\"Finished checking the model: \", description)\n",
    "    result_df = pd.concat([result_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index().sort_values('test_rmse', \n",
    "                   ascending=True)[\n",
    "                        [ \n",
    "                          'model_name',\t'train_score',\t'validation_score',\n",
    "                         \t'test_score',\t'test_std',\t'test_rmse', 'fit_time',\t'description'\n",
    "                        ]\n",
    "                              ][:40].style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lambdas = [0.0, 0.001, 0.002, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.5, 1,2,3]\n",
    "for num in reg_lambdas:\n",
    "    model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=200,\n",
    "            min_child_samples=200,\n",
    "            reg_alpha=0.01,\n",
    "            reg_lambda=num,\n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            n_estimators=60,\n",
    "            colsample_bytree=0.75,\n",
    "            subsample=0.9,\n",
    "            learning_rate=0.1)\n",
    "\n",
    "    description = \"\".join(['RegLambda ', str(num)])\n",
    "    df = model_check(model, \"Step 6 - RegLambda\", description)\n",
    "    print(\"Finished checking the model: \", description)\n",
    "    result_df = pd.concat([result_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index().sort_values('test_rmse', \n",
    "                   ascending=True)[\n",
    "                        [ \n",
    "                          'model_name',\t'train_score',\t'validation_score',\n",
    "                         \t'test_score',\t'test_std',\t'test_rmse', 'fit_time',\t'description'\n",
    "                        ]\n",
    "                              ][:40].style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix below\n",
    "\n",
    "# choosing the optimal learning rate\n",
    "\n",
    "rates = [\n",
    "       {'rate': 0.1, 'n': 60},\n",
    "       {'rate': 0.06, 'n': 100},\n",
    "       {'rate': 0.05, 'n': 120},\n",
    "       {'rate': 0.02, 'n': 300}, \n",
    "       {'rate': 0.01, 'n': 600},\n",
    "       {'rate': 0.009, 'n': 654},\n",
    "       {'rate': 0.005, 'n': 1200},\n",
    "       {'rate': 0.004, 'n': 1300},\n",
    "       {'rate': 0.002, 'n': 3000},\n",
    "       {'rate': 0.001, 'n': 6000},           \n",
    "]\n",
    "\n",
    "for rate in rates:\n",
    "    model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=200, \n",
    "            reg_alpha=0.01,\n",
    "            reg_lambda=0.0,\n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            colsample_bytree=0.75,\n",
    "            subsample=0.9,\n",
    "            n_estimators=rate['n'],\n",
    "            learning_rate=rate['rate'])\n",
    "\n",
    "    description = \"\".join(['LR ', str(rate['rate']), '; nrounds=', str(rate['n'])])\n",
    "    df = model_check(model, \"Step 7 - LR\", description)\n",
    "    print(\"Finished checking the model: \", description)\n",
    "    result_df = pd.concat([result_df, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.reset_index().sort_values('test_rmse', \n",
    "                   ascending=True)[\n",
    "                        [ \n",
    "                          'model_name',\t'train_score',\t'validation_score',\n",
    "                         \t'test_score',\t'test_std',\t'test_rmse', 'fit_time',\t'description'\n",
    "                        ]\n",
    "                              ][:40].style.background_gradient(cmap='Oranges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and predicting with the best model\n",
    "best_model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=200, \n",
    "            reg_alpha=0.01,\n",
    "            reg_lambda=0.0,\n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            colsample_bytree=0.75,\n",
    "            subsample=0.9,\n",
    "            n_estimators=6000,\n",
    "            learning_rate=0.001)\n",
    "\n",
    "X_train_final = X_train.drop(['target', 'Fold', 'grp'], axis=1, errors='ignore').copy()\n",
    "\n",
    "best_model.fit(X_train_final, y_train)\n",
    "# output the feature importance of the best model\n",
    "feat_imp = print_lightgbm_feature_importance(X_hideout, y_hideout, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the best model on the hideout set\n",
    "pred_hideout = best_model.predict(X_hideout)\n",
    "hideout_score = best_model.score(X_hideout, y_hideout.ravel())\n",
    "\n",
    "print('Score of the Regressor on the hideout set: {:.4f}'.format(hideout_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in scikit-learn >= 0.22.0 \n",
    "# https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python\n",
    "rmse = mean_squared_error(y_hideout, pred_hideout, squared=False)\n",
    "print('RMSE of the Regressor on the hideout set: {:.4f}'.format(rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Submission 1\n",
    "\n",
    "best_model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=200, \n",
    "            reg_alpha=0.01,\n",
    "            reg_lambda=0.0,\n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            colsample_bytree=0.75,\n",
    "            subsample=0.9,\n",
    "            n_estimators=1200,\n",
    "            learning_rate=0.005)\n",
    "            \n",
    "- 0.6299 on the local RMSE Check\n",
    "- 0.70382 on the public leaderboard\n",
    "- Date: Jan 20, 2021\n",
    "\n",
    "## Submission 2\n",
    "\n",
    "best_model = lgb.LGBMRegressor(\n",
    "            objective='regression',\n",
    "            metric='rmse',\n",
    "            num_leaves=200, \n",
    "            reg_alpha=0.01,\n",
    "            reg_lambda=0.0,\n",
    "            max_depth=-1, \n",
    "            random_state=314, \n",
    "            silent=True, \n",
    "            n_jobs=4, \n",
    "            colsample_bytree=0.75,\n",
    "            subsample=0.9,\n",
    "            n_estimators=6000,\n",
    "            learning_rate=0.001)\n",
    "            \n",
    "- 0.6299 on the local RMSE check\n",
    "- 0.70387 on the public leaderboard\n",
    "- Date: Jan 20, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on the test dataset\n",
    "pred_test = best_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#save sumbmission to a file\n",
    "subm['target'] = pred_test\n",
    "subm.to_csv('submission.csv', index=False) # 0.70382 on the public leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We are done. That is all, folks!')\n",
    "finish_time = dt.datetime.now()\n",
    "print(\"Finished at \", finish_time)\n",
    "elapsed = finish_time - start_time\n",
    "print(\"Elapsed time: \", elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install git+https://github.com/AutoViML/featurewiz.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime as dt\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.offline\n",
    "\n",
    "\n",
    "# read data\n",
    "in_kaggle = False\n",
    "\n",
    "\n",
    "def get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n",
    "    train_path = ''\n",
    "    test_path = ''\n",
    "    sample_submission_path = ''\n",
    "\n",
    "    if is_in_kaggle:\n",
    "        # running in Kaggle, inside the competition\n",
    "        train_path = '../input/tabular-playground-series-jan-2021/train.csv'\n",
    "        test_path = '../input/tabular-playground-series-jan-2021/test.csv'\n",
    "        sample_submission_path = '../input/tabular-playground-series-jan-2021/sample_submission.csv'\n",
    "    else:\n",
    "        # running locally\n",
    "        train_path = 'data/train.csv'\n",
    "        test_path = 'data/test.csv'\n",
    "        sample_submission_path = 'data/sample_submission.csv'\n",
    "\n",
    "    return train_path, test_path, sample_submission_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2021-01-17 11:10:53.505686\n"
     ]
    }
   ],
   "source": [
    "# main flow\n",
    "start_time = dt.datetime.now()\n",
    "print(\"Started at \", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the training set and labels\n",
    "train_set_path, test_set_path, sample_subm_path = get_data_file_path(in_kaggle)\n",
    "\n",
    "df_train = pd.read_csv(train_set_path)\n",
    "df_test = pd.read_csv(test_set_path)\n",
    "\n",
    "subm = pd.read_csv(sample_subm_path)\n",
    "\n",
    "# list of feature columns\n",
    "feature_list = [col for col in df_train.columns if col.startswith('cont')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300000 entries, 0 to 299999\n",
      "Data columns (total 16 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      300000 non-null  int64  \n",
      " 1   cont1   300000 non-null  float64\n",
      " 2   cont2   300000 non-null  float64\n",
      " 3   cont3   300000 non-null  float64\n",
      " 4   cont4   300000 non-null  float64\n",
      " 5   cont5   300000 non-null  float64\n",
      " 6   cont6   300000 non-null  float64\n",
      " 7   cont7   300000 non-null  float64\n",
      " 8   cont8   300000 non-null  float64\n",
      " 9   cont9   300000 non-null  float64\n",
      " 10  cont10  300000 non-null  float64\n",
      " 11  cont11  300000 non-null  float64\n",
      " 12  cont12  300000 non-null  float64\n",
      " 13  cont13  300000 non-null  float64\n",
      " 14  cont14  300000 non-null  float64\n",
      " 15  target  300000 non-null  float64\n",
      "dtypes: float64(15), int64(1)\n",
      "memory usage: 36.6 MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional feature engineering routines\n",
    "\n",
    "# Function to extract common stats features\n",
    "def add_stat_features(\n",
    "    train: pd.DataFrame, \n",
    "    test: pd.DataFrame, \n",
    "    features_c: List[str]) -> [pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    for df in [train, test]:\n",
    "        df['c_sum'] = df[features_c].sum(axis=1)\n",
    "        df['c_mean'] = df[features_c].mean(axis=1)\n",
    "        df['c_std'] = df[features_c].std(axis=1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis=1)\n",
    "        df['c_skew'] = df[features_c].skew(axis=1)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "# function to add squared c-features\n",
    "def add_squared(\n",
    "    train: pd.DataFrame, \n",
    "    test: pd.DataFrame, \n",
    "    features_c: List[str]) -> [pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    for df in [train, test]:\n",
    "        for feature in features_c:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2\n",
    "    return train, test\n",
    "\n",
    "# function to add simple genetic features\n",
    "def add_genetic_features(\n",
    "    train: pd.DataFrame, \n",
    "    test: pd.DataFrame, \n",
    "    features_c: List[str],\n",
    "    add_plus_features=True,\n",
    "    add_minus_features=False,\n",
    "    add_product_features=False,\n",
    "    add_divided_features=False,\n",
    "    add_plus_by_minus_features=False,\n",
    "    add_plus_div_by_minus_features=False\n",
    ") -> [pd.DataFrame, pd.DataFrame]:\n",
    "    \n",
    "    small_val = 0.00001\n",
    "    for df in [train, test]:\n",
    "        for col1 in features_c:\n",
    "            for col2 in features_c:\n",
    "                if col1 != col2:\n",
    "                    if add_plus_features:\n",
    "                        df[f'{col1}_plus_{col2}'] = df[col1] + df[col2]\n",
    "                    if add_minus_features:\n",
    "                        df[f'{col1}_minus_{col2}'] = df[col1] - df[col2]\n",
    "                    if add_product_features:\n",
    "                        df[f'{col1}_prod_{col2}'] = df[col1] * df[col2]\n",
    "                    if add_divided_features:\n",
    "                        df[f'{col1}_div_{col2}'] = df[col1] / ( df[col2] + small_val)\n",
    "                    if add_plus_by_minus_features:\n",
    "                        df[f'{col1}_qq_{col2}'] = (df[col1] + df[col2]) * (df[col1] - df[col2])\n",
    "                    if add_plus_div_by_minus_features:\n",
    "                        df[f'{col1}_div2_{col2}'] = (df[col1] - df[col2]) / (df[col1] + df[col2] + small_val)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# run additional feature engineering\n",
    "#df_train, df_test = add_stat_features(df_train, df_test, feature_list)\n",
    "#df_train, df_test = add_squared(df_train, df_test, feature_list)\n",
    "\n",
    "df_train, df_test = add_genetic_features(\n",
    "    train=df_train, \n",
    "    test=df_test, \n",
    "    features_c=feature_list,\n",
    "    add_plus_features=False,\n",
    "    add_minus_features=False,\n",
    "    add_product_features=False,\n",
    "    add_divided_features=True,\n",
    "    add_plus_by_minus_features=False,\n",
    "    add_plus_div_by_minus_features=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported featurewiz: Auto_ViML's feature engg and selection library. Version=0.0.14\n",
      "output = featurewiz(dataname, target, corr_limit=0.70,\n",
      "                    verbose=2, sep=',', header=0, test_data='',\n",
      "                    feature_engg='', category_encoders='')\n",
      "Let featurewiz add features to your data! Set 'feature_engg' as: 'interactions' or 'groupby' or 'target'\n",
      "                                \n",
      "Skipping feature engineering since no feature_engg input...\n",
      "Skipping category encoding since no category encoders specified in input...\n",
      "Shape of your Data Set loaded: (300000, 198)\n",
      "    No GPU active on this device\n",
      "    Running XGBoost using CPU parameters\n",
      "############## C L A S S I F Y I N G  V A R I A B L E S  ####################\n",
      "Classifying variables in data set...\n",
      "    197 Predictors classified...\n",
      "        1 variable(s) removed since they were ID or low-information variables\n",
      "#### Single_Label Regression Feature Selection Started ####\n",
      "Searching for highly correlated variables from 196 variables using SULOV method\n",
      "#####  SULOV : Searching for Uncorrelated List Of Variables (takes time...) ############\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from featurewiz import featurewiz\n",
    "\n",
    "df_train_out, df_test_out = featurewiz(\n",
    "    dataname=df_train, \n",
    "    target='target', \n",
    "    corr_limit=0.7, \n",
    "    verbose=0, \n",
    "    sep=\",\",\n",
    "    header=0,\n",
    "    test_data=df_test, \n",
    "    feature_engg=\"\", \n",
    "    category_encoders=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Selected variables:')\n",
    "print('---------------------')\n",
    "print(df_train_out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we can see the following feature choices made by *featurewiz*\n",
    "\n",
    "- Selected (13) vars: 'cont4', 'cont13', 'cont3', 'cont7', 'cont2', 'cont12', 'cont14', 'cont9', 'cont4_prod_cont3', 'cont5', 'cont4_prod_cont2', 'cont11_prod_cont4', 'cont11_prod_cont3', 'cont8', 'cont13_prod_cont3', 'cont12_prod_cont5', 'cont14_prod_cont11', 'cont8_prod_cont3', 'cont14_prod_cont3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We are done. That is all, folks!')\n",
    "finish_time = dt.datetime.now()\n",
    "print(\"Finished at \", finish_time)\n",
    "elapsed = finish_time - start_time\n",
    "print(\"Elapsed time: \", elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

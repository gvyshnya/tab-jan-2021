{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n",
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "http://github.com/matplotlib/matplotlib/blob/master/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "# inspired by https://www.kaggle.com/hamditarek/tabular-playground-series-xgboost-lightgbm\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime as dt\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import plotly.offline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, cross_val_score, cross_validate\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# read data\n",
    "in_kaggle = False\n",
    "\n",
    "\n",
    "def get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n",
    "    train_path = ''\n",
    "    test_path = ''\n",
    "    sample_submission_path = ''\n",
    "\n",
    "    if is_in_kaggle:\n",
    "        # running in Kaggle, inside the competition\n",
    "        train_path = '../input/tabular-playground-series-jan-2021/train.csv'\n",
    "        test_path = '../input/tabular-playground-series-jan-2021/test.csv'\n",
    "        sample_submission_path = '../input/tabular-playground-series-jan-2021/sample_submission.csv'\n",
    "    else:\n",
    "        # running locally\n",
    "        train_path = 'data/train.csv'\n",
    "        test_path = 'data/test.csv'\n",
    "        sample_submission_path = 'data/sample_submission.csv'\n",
    "\n",
    "    return train_path, test_path, sample_submission_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2021-01-29 18:52:29.741648\n"
     ]
    }
   ],
   "source": [
    "# main flow\n",
    "start_time = dt.datetime.now()\n",
    "print(\"Started at \", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the training set and labels\n",
    "train_set_path, test_set_path, sample_subm_path = get_data_file_path(in_kaggle)\n",
    "\n",
    "df_train = pd.read_csv(train_set_path)\n",
    "df_test = pd.read_csv(test_set_path)\n",
    "\n",
    "subm = pd.read_csv(sample_subm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.670390</td>\n",
       "      <td>0.811300</td>\n",
       "      <td>0.643968</td>\n",
       "      <td>0.291791</td>\n",
       "      <td>0.284117</td>\n",
       "      <td>0.855953</td>\n",
       "      <td>0.890700</td>\n",
       "      <td>0.285542</td>\n",
       "      <td>0.558245</td>\n",
       "      <td>0.779418</td>\n",
       "      <td>0.921832</td>\n",
       "      <td>0.866772</td>\n",
       "      <td>0.878733</td>\n",
       "      <td>0.305411</td>\n",
       "      <td>7.243043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.388053</td>\n",
       "      <td>0.621104</td>\n",
       "      <td>0.686102</td>\n",
       "      <td>0.501149</td>\n",
       "      <td>0.643790</td>\n",
       "      <td>0.449805</td>\n",
       "      <td>0.510824</td>\n",
       "      <td>0.580748</td>\n",
       "      <td>0.418335</td>\n",
       "      <td>0.432632</td>\n",
       "      <td>0.439872</td>\n",
       "      <td>0.434971</td>\n",
       "      <td>0.369957</td>\n",
       "      <td>0.369484</td>\n",
       "      <td>8.203331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.834950</td>\n",
       "      <td>0.227436</td>\n",
       "      <td>0.301584</td>\n",
       "      <td>0.293408</td>\n",
       "      <td>0.606839</td>\n",
       "      <td>0.829175</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>0.558771</td>\n",
       "      <td>0.587603</td>\n",
       "      <td>0.823312</td>\n",
       "      <td>0.567007</td>\n",
       "      <td>0.677708</td>\n",
       "      <td>0.882938</td>\n",
       "      <td>0.303047</td>\n",
       "      <td>7.776091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.820708</td>\n",
       "      <td>0.160155</td>\n",
       "      <td>0.546887</td>\n",
       "      <td>0.726104</td>\n",
       "      <td>0.282444</td>\n",
       "      <td>0.785108</td>\n",
       "      <td>0.752758</td>\n",
       "      <td>0.823267</td>\n",
       "      <td>0.574466</td>\n",
       "      <td>0.580843</td>\n",
       "      <td>0.769594</td>\n",
       "      <td>0.818143</td>\n",
       "      <td>0.914281</td>\n",
       "      <td>0.279528</td>\n",
       "      <td>6.957716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.935278</td>\n",
       "      <td>0.421235</td>\n",
       "      <td>0.303801</td>\n",
       "      <td>0.880214</td>\n",
       "      <td>0.665610</td>\n",
       "      <td>0.830131</td>\n",
       "      <td>0.487113</td>\n",
       "      <td>0.604157</td>\n",
       "      <td>0.874658</td>\n",
       "      <td>0.863427</td>\n",
       "      <td>0.983575</td>\n",
       "      <td>0.900464</td>\n",
       "      <td>0.935918</td>\n",
       "      <td>0.435772</td>\n",
       "      <td>7.951046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     cont1     cont2     cont3     cont4     cont5     cont6     cont7  \\\n",
       "0   1  0.670390  0.811300  0.643968  0.291791  0.284117  0.855953  0.890700   \n",
       "1   3  0.388053  0.621104  0.686102  0.501149  0.643790  0.449805  0.510824   \n",
       "2   4  0.834950  0.227436  0.301584  0.293408  0.606839  0.829175  0.506143   \n",
       "3   5  0.820708  0.160155  0.546887  0.726104  0.282444  0.785108  0.752758   \n",
       "4   8  0.935278  0.421235  0.303801  0.880214  0.665610  0.830131  0.487113   \n",
       "\n",
       "      cont8     cont9    cont10    cont11    cont12    cont13    cont14  \\\n",
       "0  0.285542  0.558245  0.779418  0.921832  0.866772  0.878733  0.305411   \n",
       "1  0.580748  0.418335  0.432632  0.439872  0.434971  0.369957  0.369484   \n",
       "2  0.558771  0.587603  0.823312  0.567007  0.677708  0.882938  0.303047   \n",
       "3  0.823267  0.574466  0.580843  0.769594  0.818143  0.914281  0.279528   \n",
       "4  0.604157  0.874658  0.863427  0.983575  0.900464  0.935918  0.435772   \n",
       "\n",
       "     target  \n",
       "0  7.243043  \n",
       "1  8.203331  \n",
       "2  7.776091  \n",
       "3  6.957716  \n",
       "4  7.951046  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# target labels list\n",
    "target = 'target'\n",
    "\n",
    "# drop sig_id from train and test sets\n",
    "df_train = df_train.drop(['id'], axis=1, errors='ignore')\n",
    "df_test = df_test.drop(['id'], axis=1, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratified continuous target split\n",
    "# courtesy @tolgadincer and his contribution for https://www.kaggle.com/tolgadincer/continuous-target-stratification\n",
    "\n",
    "def create_folds(df, n_s=5, n_grp=None):\n",
    "    df['Fold'] = -1\n",
    "    \n",
    "    if n_grp is None:\n",
    "        skf = KFold(n_splits=n_s, random_state=42, shuffle=True)\n",
    "        target = df.target\n",
    "    else:\n",
    "        skf = StratifiedKFold(n_splits=n_s, random_state=42, shuffle=False)\n",
    "        df['grp'] = pd.cut(df.target, n_grp, labels=False)\n",
    "        target = df.grp\n",
    "    \n",
    "    for fold_no, (t, v) in enumerate(skf.split(target, target)):\n",
    "        df.loc[v, 'Fold'] = fold_no\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb # LightGBM Model\n",
    "\n",
    "\n",
    "#Additional scklearn functions\n",
    "from sklearn import metrics   \n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_validate\n",
    "\n",
    "\n",
    "# Setting stratified kfold upon the continuous target for future use\n",
    "kfolds = 5\n",
    "df_train = create_folds(df_train, n_s=kfolds) #, n_grp=1000\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "# set a hideout fold \n",
    "\n",
    "y = df_train['target']\n",
    "X_train, X_hideout, y_train, y_hideout = train_test_split(df_train, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "X_hideout = X_hideout.drop(['target', 'Fold', 'grp'], axis=1, errors='ignore').copy()\n",
    "\n",
    "def print_lightgbm_feature_importance(X, y, estimator):\n",
    "    #Print Feature Importance:\n",
    "    estimator.fit(X, y)\n",
    "    predictors = X.columns\n",
    "\n",
    "    feat_imp = pd.Series(estimator.feature_importances_, predictors).sort_values(ascending=False)\n",
    "    feat_imp.nlargest(30).plot(kind='barh', title='Feature Importances', figsize=(8,10))\n",
    "    plt.ylabel('Feature Importance Score')\n",
    "    df = feat_imp.to_frame().reset_index()\n",
    "    df = df.rename(columns={'index': 'predictor', 0: \"fi_score\"})\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def model_check(estimator, model_name, model_description):\n",
    "    model_table = pd.DataFrame()\n",
    "\n",
    "    for i in range(0, kfolds):\n",
    "        fold_fit_start_time = dt.datetime.now()\n",
    "        \n",
    "        X_valid = X_train[X_train['Fold'] == i]\n",
    "        y_valid = X_valid['target']\n",
    "        X_valid = X_valid.drop(['target', 'Fold', 'grp'], axis=1, errors='ignore')\n",
    "        \n",
    "        X_tr = X_train[X_train['Fold'] != i]\n",
    "        y_tr = X_tr['target']\n",
    "        X_tr = X_tr.drop(['target', 'Fold', 'grp'], axis=1, errors='ignore')\n",
    "    \n",
    "\n",
    "        fit_model = estimator.fit(X_tr, y_tr)\n",
    "        \n",
    "        pred_tr = estimator.predict(X_tr)\n",
    "        pred_val = estimator.predict(X_valid)\n",
    "\n",
    "        train_score = estimator.score(X_tr, y_tr.values.ravel())\n",
    "        validation_score = estimator.score(X_valid, y_valid.values.ravel())\n",
    "\n",
    "        print('Accuracy of the Regressor on the training set, fold {}: {:.4f}'.format(i, train_score))\n",
    "        print('Accuracy of the Regressor on the validation set, fold {}: {:.4f}'.format(i, validation_score))\n",
    "        \n",
    "        X_hide = X_hideout.copy()\n",
    "        pred_hideout = estimator.predict(X_hide)\n",
    "\n",
    "        hideout_score = estimator.score(X_hide, y_hideout.values.ravel())\n",
    "        print('Accuracy of the Regressor on the hide-out set, fold {}: {:.4f}'.format(i, hideout_score))\n",
    "        \n",
    "        rmse = mean_squared_error(y_hideout, pred_hideout, squared=False)\n",
    "        print('RMSE of the Regressor on the hideout set, fold {}: {:.4f}'.format(i, rmse))\n",
    "\n",
    "        fold_fit_end_time = dt.datetime.now()\n",
    "\n",
    "        fit_time = fold_fit_end_time - fold_fit_start_time\n",
    "\n",
    "        cv_attributes = {\n",
    "            'train_score': round(train_score, 4),\n",
    "            'validation_score': round(validation_score, 4),\n",
    "            'test_score': round(hideout_score, 4),\n",
    "            'test_rmse': round(rmse, 4),\n",
    "            'fit_time': fit_time,\n",
    "        }\n",
    "\n",
    "        if i == 0:\n",
    "            # the initial fold, just initializing the results dataframe\n",
    "            cv_results = pd.DataFrame(data=[cv_attributes])\n",
    "        else:\n",
    "            # appending the results dataframe\n",
    "            fold_result = pd.DataFrame(data=[cv_attributes])\n",
    "            cv_results = pd.concat([cv_results, fold_result])\n",
    "\n",
    "        del X_tr, X_valid, X_hide, y_tr, y_valid\n",
    "\n",
    "    train_score = cv_results['train_score'].mean()\n",
    "    validation_score = cv_results['validation_score'].mean()\n",
    "    test_score = cv_results['test_score'].mean()\n",
    "    test_rmse = cv_results['test_rmse'].mean()\n",
    "    test_std = cv_results['test_score'].std()\n",
    "    fit_time = cv_results['fit_time'].mean()\n",
    "\n",
    "    attributes = {\n",
    "        'model_name': model_name,\n",
    "        'train_score': train_score,\n",
    "        'validation_score': validation_score,\n",
    "        'test_score': test_score,\n",
    "        'test_std': test_std,\n",
    "        'test_rmse': test_rmse,\n",
    "        'fit_time': fit_time,\n",
    "        'description': model_description,\n",
    "    }\n",
    "    \n",
    "    model_table = pd.DataFrame(data=[attributes])\n",
    "    return model_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:52:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { metric_period, silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# params for XGB are taked from this great kernel https://www.kaggle.com/hamzaghanmi/xgboost-hyperparameter-tuning-using-optuna \n",
    "# by Hamza Ghanmi\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "                 colsample_bytree=0.5,\n",
    "                 alpha=0.01563,\n",
    "                 #gamma=0.0,\n",
    "                 learning_rate=0.01,\n",
    "                 max_depth=15,\n",
    "                 min_child_weight=257,\n",
    "                 n_estimators=4000,                                                                  \n",
    "                 #reg_alpha=0.9,\n",
    "                 reg_lambda=0.003,\n",
    "                 subsample=0.7,\n",
    "                 random_state=2020,\n",
    "                 metric_period=100,\n",
    "                 silent=1)\n",
    "\n",
    "# fit the baseline model with the training data\n",
    "result_df = model_check(model, \"Initial model\", \"Initial baseline\")\n",
    "display(result_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and predicting with the best model\n",
    "best_model = model\n",
    "\n",
    "X_train_final = X_train.drop(['target', 'Fold', 'grp'], axis=1, errors='ignore').copy()\n",
    "\n",
    "best_model.fit(X_train_final, y_train)\n",
    "# output the feature importance of the best model\n",
    "feat_imp = print_lightgbm_feature_importance(X_hideout, y_hideout, best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting with the best model on the hideout set\n",
    "pred_hideout = best_model.predict(X_hideout)\n",
    "hideout_score = best_model.score(X_hideout, y_hideout.ravel())\n",
    "\n",
    "print('Score of the Regressor on the hideout set: {:.4f}'.format(hideout_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in scikit-learn >= 0.22.0 \n",
    "# https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python\n",
    "rmse = mean_squared_error(y_hideout, pred_hideout, squared=False)\n",
    "print('RMSE of the Regressor on the hideout set: {:.4f}'.format(rmse))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Submission 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting on the test dataset\n",
    "pred_test = best_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#save sumbmission to a file\n",
    "subm['target'] = pred_test\n",
    "subm.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We are done. That is all, folks!')\n",
    "finish_time = dt.datetime.now()\n",
    "print(\"Finished at \", finish_time)\n",
    "elapsed = finish_time - start_time\n",
    "print(\"Elapsed time: \", elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

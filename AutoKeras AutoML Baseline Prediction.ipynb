{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import datetime as dt\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started at  2021-01-31 22:11:20.517325\n"
     ]
    }
   ],
   "source": [
    "# main flow\n",
    "start_time = dt.datetime.now()\n",
    "print(\"Started at \", start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_kaggle = False\n",
    "\n",
    "\n",
    "def get_data_file_path(is_in_kaggle: bool) -> Tuple[str, str, str]:\n",
    "    train_path = ''\n",
    "    test_path = ''\n",
    "    sample_submission_path = ''\n",
    "\n",
    "    if is_in_kaggle:\n",
    "        # running in Kaggle, inside the competition\n",
    "        train_path = '../input/tabular-playground-series-jan-2021/train.csv'\n",
    "        test_path = '../input/tabular-playground-series-jan-2021/test.csv'\n",
    "        sample_submission_path = '../input/tabular-playground-series-jan-2021/sample_submission.csv'\n",
    "    else:\n",
    "        # running locally\n",
    "        train_path = 'data/train.csv'\n",
    "        test_path = 'data/test.csv'\n",
    "        sample_submission_path = 'data/sample_submission.csv'\n",
    "\n",
    "    return train_path, test_path, sample_submission_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get the training set and labels\n",
    "train_set_path, test_set_path, sample_subm_path = get_data_file_path(in_kaggle)\n",
    "\n",
    "df_train = pd.read_csv(train_set_path)\n",
    "df_test = pd.read_csv(test_set_path)\n",
    "\n",
    "subm = pd.read_csv(sample_subm_path)\n",
    "\n",
    "# list of basic raw features\n",
    "feature_list = [col for col in df_train.columns if col.startswith('cont')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210000, 14) (90000, 14) (210000,) (90000,)\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# do the train-test split for the model evaluation purpose\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df_train[feature_list] \n",
    "X_test = df_test[feature_list] \n",
    "y = df_train['target']\n",
    "# separate into train and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 Complete [00h 07m 14s]\n",
      "val_loss: 0.5114156603813171\n",
      "\n",
      "Best val_loss So Far: 0.5075059533119202\n",
      "Total elapsed time: 01h 40m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 5.0338 - mean_squared_error: 5.0338\n",
      "Epoch 2/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 1.0593 - mean_squared_error: 1.0593\n",
      "Epoch 3/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.6733 - mean_squared_error: 0.6733\n",
      "Epoch 4/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5500 - mean_squared_error: 0.5500\n",
      "Epoch 5/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5247 - mean_squared_error: 0.5247\n",
      "Epoch 6/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5196 - mean_squared_error: 0.5196\n",
      "Epoch 7/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5182 - mean_squared_error: 0.5182\n",
      "Epoch 8/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5170 - mean_squared_error: 0.5170\n",
      "Epoch 9/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5156 - mean_squared_error: 0.5156\n",
      "Epoch 10/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5153 - mean_squared_error: 0.5153\n",
      "Epoch 11/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5146 - mean_squared_error: 0.5146\n",
      "Epoch 12/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5139 - mean_squared_error: 0.5139\n",
      "Epoch 13/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5134 - mean_squared_error: 0.5134\n",
      "Epoch 14/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5129 - mean_squared_error: 0.5129\n",
      "Epoch 15/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5124 - mean_squared_error: 0.5124\n",
      "Epoch 16/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5122 - mean_squared_error: 0.5122\n",
      "Epoch 17/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5121 - mean_squared_error: 0.5121\n",
      "Epoch 18/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5119 - mean_squared_error: 0.5119\n",
      "Epoch 19/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5114 - mean_squared_error: 0.5114\n",
      "Epoch 20/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5115 - mean_squared_error: 0.5115\n",
      "Epoch 21/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5115 - mean_squared_error: 0.5115\n",
      "Epoch 22/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5112 - mean_squared_error: 0.5112\n",
      "Epoch 23/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5108 - mean_squared_error: 0.5108\n",
      "Epoch 24/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5107 - mean_squared_error: 0.5107\n",
      "Epoch 25/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5107 - mean_squared_error: 0.5107\n",
      "Epoch 26/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5101 - mean_squared_error: 0.5101\n",
      "Epoch 27/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5102 - mean_squared_error: 0.5102\n",
      "Epoch 28/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5105 - mean_squared_error: 0.5105\n",
      "Epoch 29/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5100 - mean_squared_error: 0.5100\n",
      "Epoch 30/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5097 - mean_squared_error: 0.5097\n",
      "Epoch 31/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5101 - mean_squared_error: 0.5101\n",
      "Epoch 32/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5097 - mean_squared_error: 0.5097\n",
      "Epoch 33/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5093 - mean_squared_error: 0.5093\n",
      "Epoch 34/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5096 - mean_squared_error: 0.5096\n",
      "Epoch 35/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5093 - mean_squared_error: 0.5093\n",
      "Epoch 36/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5093 - mean_squared_error: 0.5093\n",
      "Epoch 37/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5092 - mean_squared_error: 0.5092\n",
      "Epoch 38/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5093 - mean_squared_error: 0.5093\n",
      "Epoch 39/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5092 - mean_squared_error: 0.5092\n",
      "Epoch 40/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5094 - mean_squared_error: 0.5094\n",
      "Epoch 41/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5094 - mean_squared_error: 0.5094\n",
      "Epoch 42/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5089 - mean_squared_error: 0.5089\n",
      "Epoch 43/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5092 - mean_squared_error: 0.5092\n",
      "Epoch 44/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5086 - mean_squared_error: 0.5086\n",
      "Epoch 45/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5089 - mean_squared_error: 0.5089\n",
      "Epoch 46/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5085 - mean_squared_error: 0.5085\n",
      "Epoch 47/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5085 - mean_squared_error: 0.5085\n",
      "Epoch 48/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5082 - mean_squared_error: 0.5082\n",
      "Epoch 49/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5081 - mean_squared_error: 0.5081\n",
      "Epoch 50/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5090 - mean_squared_error: 0.5090\n",
      "Epoch 51/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5086 - mean_squared_error: 0.5086\n",
      "Epoch 52/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5085 - mean_squared_error: 0.5085\n",
      "Epoch 53/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5082 - mean_squared_error: 0.5082\n",
      "Epoch 54/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5085 - mean_squared_error: 0.5085\n",
      "Epoch 55/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5083 - mean_squared_error: 0.5083\n",
      "Epoch 56/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5087 - mean_squared_error: 0.5087\n",
      "Epoch 57/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5082 - mean_squared_error: 0.5082\n",
      "Epoch 58/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5081 - mean_squared_error: 0.5081\n",
      "Epoch 59/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5080 - mean_squared_error: 0.5080\n",
      "Epoch 60/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5083 - mean_squared_error: 0.5083\n",
      "Epoch 61/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5084 - mean_squared_error: 0.5084\n",
      "Epoch 62/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5081 - mean_squared_error: 0.5081\n",
      "Epoch 63/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5080 - mean_squared_error: 0.5080\n",
      "Epoch 64/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5081 - mean_squared_error: 0.5081\n",
      "Epoch 65/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5082 - mean_squared_error: 0.5082\n",
      "Epoch 66/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5079 - mean_squared_error: 0.5079\n",
      "Epoch 67/67\n",
      "6563/6563 [==============================] - 7s 1ms/step - loss: 0.5079 - mean_squared_error: 0.5079\n",
      "INFO:tensorflow:Assets written to: .\\structured_data_regressor\\best_model\\assets\n",
      "2813/2813 [==============================] - 2s 771us/step - loss: 0.5094 - mean_squared_error: 0.5094\n",
      "MSE: 0.509\n"
     ]
    }
   ],
   "source": [
    "from autokeras import StructuredDataRegressor\n",
    "# define the search\n",
    "# max 15 models to try\n",
    "search = StructuredDataRegressor(max_trials=29, loss='mean_squared_error')\n",
    "\n",
    "# perform the search\n",
    "search.fit(x=X_train, y=y_train, verbose=1)\n",
    "# evaluate the model\n",
    "mse, _ = search.evaluate(X_val, y_val, verbose=1)\n",
    "print('MSE: %.3f' % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict with the best model on the test set\n",
    "yhat = search.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 14)]              0         \n",
      "_________________________________________________________________\n",
      "multi_category_encoding (Mul (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "normalization (Normalization (None, 14)                29        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                480       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "regression_head_1 (Dense)    (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,598\n",
      "Trainable params: 1,569\n",
      "Non-trainable params: 29\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get the best performing model\n",
    "model = search.export_model()\n",
    "# summarize the loaded model\n",
    "model.summary()\n",
    "# save the best performing model to file\n",
    "model.save('model_insurance.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package the final submission file\n",
    "subm['target'] = yhat\n",
    "subm.to_csv('autokeras_automl_submission.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission results\n",
    "\n",
    "## Best Model out of 15 Trials\n",
    "\n",
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "_________________________________________________________________\n",
    "input_1 (InputLayer)         (None, 14)             0         \n",
    "_________________________________________________________________\n",
    "multi_category_encoding (Mul (None, 14)                0         \n",
    "_________________________________________________________________\n",
    "normalization (Normalization (None, 14)                29        \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 32)                480       \n",
    "_________________________________________________________________\n",
    "re_lu (ReLU)                 (None, 32)                0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 32)                1056      \n",
    "_________________________________________________________________\n",
    "re_lu_1 (ReLU)               (None, 32)                0         \n",
    "_________________________________________________________________\n",
    "regression_head_1 (Dense)    (None, 1)                 33        \n",
    "_________________________________________________________________\n",
    "Total params: 1,598\n",
    "Trainable params: 1,569\n",
    "Non-trainable params: 29\n",
    "\n",
    "- RMSE on the public leaderboard: 0.71698\n",
    "- MSE on the local validation: 0.511\n",
    "- RMSE on the local validation: 0.714947551\n",
    "- Training time: 01h 5m 14s\n",
    "\n",
    "## Submission 2\n",
    "\n",
    "Model: \"model\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "_________________________________________________________________\n",
    "input_1 (InputLayer)          (None, 14)               0         \n",
    "_________________________________________________________________\n",
    "multi_category_encoding (Mul (None, 14)                0         \n",
    "_________________________________________________________________\n",
    "normalization (Normalization (None, 14)                29        \n",
    "_________________________________________________________________\n",
    "dense (Dense)                (None, 32)                480       \n",
    "_________________________________________________________________\n",
    "re_lu (ReLU)                 (None, 32)                0         \n",
    "_________________________________________________________________\n",
    "dense_1 (Dense)              (None, 32)                1056      \n",
    "_________________________________________________________________\n",
    "re_lu_1 (ReLU)               (None, 32)                0         \n",
    "_________________________________________________________________\n",
    "dropout (Dropout)            (None, 32)                0         \n",
    "_________________________________________________________________\n",
    "regression_head_1 (Dense)    (None, 1)                 33        \n",
    "\n",
    "Total params: 1,598\n",
    "Trainable params: 1,569\n",
    "Non-trainable params: 29\n",
    "\n",
    "\n",
    "- RMSE on the public leaderboard: 0.71490\n",
    "- MSE on the local validation: 0.509\n",
    "- RMSE on the local validation: 0,712393852\n",
    "- Training time: 01h 40m 35s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are done. That is all, folks!\n",
      "Finished at  2021-02-01 00:00:25.203076\n",
      "Elapsed time:  1:49:04.685751\n"
     ]
    }
   ],
   "source": [
    "print('We are done. That is all, folks!')\n",
    "finish_time = dt.datetime.now()\n",
    "print(\"Finished at \", finish_time)\n",
    "elapsed = finish_time - start_time\n",
    "print(\"Elapsed time: \", elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
